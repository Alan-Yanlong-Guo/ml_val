{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_load_xy(years, dy=0, dq=1, save_dir='xy_data', aq='q'):\n",
    "    DATA_FOLDER = '/Users/mmw/Documents/GitHub/ml_val/data_all'\n",
    "    folder = '_'.join(['xy', aq, str(dy), str(dq)])\n",
    "    if not os.path.exists(os.path.join(DATA_FOLDER, folder)):\n",
    "        raise Exception('Preprocessed xy data folder not found')\n",
    "    if not os.path.exists(os.path.join(DATA_FOLDER, save_dir)):\n",
    "        os.mkdir(os.path.join(DATA_FOLDER, save_dir))\n",
    "\n",
    "    x_df_set, y_df_set = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    for year in years:\n",
    "        with open(os.path.join(DATA_FOLDER, folder, '_'.join(['x', str(year)]) + '.pkl'), 'rb') as handle:\n",
    "            x_df_ = pickle.load(handle)\n",
    "        with open(os.path.join(DATA_FOLDER, folder, '_'.join(['y', str(year)]) + '.pkl'), 'rb') as handle:\n",
    "            y_df_ = pickle.load(handle)\n",
    "        x_df_set = pd.concat([x_df_set, x_df_], axis=0)\n",
    "        y_df_set = pd.concat([y_df_set, y_df_], axis=0)\n",
    "\n",
    "    return x_df_set, y_df_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_process(tr_start=1975, tr_duration=30, ts_duration=1, dy=0, dq=1, plot=True):\n",
    "    \n",
    "    tr_years = [tr_start+i for i in range(tr_duration)]\n",
    "    print(tr_years)\n",
    "    ts_years = [tr_start+tr_duration+i for i in range(ts_duration)]\n",
    "    print(ts_years)\n",
    "    \n",
    "    x_tr_set, y_tr_set = run_load_xy(tr_years, dy=dy, dq=dq)\n",
    "    x_ts_set, y_ts_set = run_load_xy(ts_years, dy=dy, dq=dq)\n",
    "    \n",
    "    x_tr = x_tr_set.iloc[:,5:]\n",
    "    x_tr.replace([np.inf, -np.inf, 'inf', '-inf'], np.NaN, inplace=True)\n",
    "    x_tr = x_tr.fillna(0).astype('float32')\n",
    "    \n",
    "    y_tr = y_tr_set.iloc[:,5:]\n",
    "    y_tr.replace([np.inf, -np.inf, 'inf', '-inf'], np.NaN, inplace=True)\n",
    "    y_tr = y_tr.fillna(0).astype('float32')\n",
    "    \n",
    "    x_ts = x_ts_set.iloc[:,5:]\n",
    "    x_ts.replace([np.inf, -np.inf, 'inf', '-inf'], np.NaN, inplace=True)\n",
    "    x_ts = x_ts.fillna(0).astype('float32')\n",
    "    \n",
    "    y_ts = y_ts_set.iloc[:,5:]\n",
    "    y_ts.replace([np.inf, -np.inf, 'inf', '-inf'], np.NaN, inplace=True)\n",
    "    y_ts = y_ts.fillna(0).astype('float32')\n",
    "    \n",
    "    oosr2 = {}\n",
    "    oosr2single = {}\n",
    "    max1 = {}\n",
    "    max2 = {}\n",
    "    max3= {}\n",
    "    max4 = {}\n",
    "    max5 = {}\n",
    "\n",
    "    def single_feature_oosr2(item, x_tr=x_tr, y_tr=y_tr, x_ts=x_ts, y_ts=y_ts, \n",
    "                             param_test = {'max_depth': [1]}):\n",
    "        try:\n",
    "            _ = x_tr[item].values.shape[1]\n",
    "            x_tr_single = x_tr[item].values[:, 0].reshape(-1, 1)\n",
    "            y_tr_single = y_tr[item].values\n",
    "            x_ts_single = x_ts[item].values[:, 0].reshape(-1, 1)\n",
    "            y_ts_single = y_ts[item].values\n",
    "        except IndexError:\n",
    "            x_tr_single = x_tr[item].values.reshape(-1, 1)\n",
    "            y_tr_single = y_tr[item].values\n",
    "            x_ts_single = x_ts[item].values.reshape(-1, 1)\n",
    "            y_ts_single = y_ts[item].values \n",
    "\n",
    "        mod = LGBMRegressor(objective='regression_l2', zero_as_missing=True)\n",
    "        clf = sklearn.model_selection.GridSearchCV(mod , param_grid = param_test, scoring='r2', cv=3)\n",
    "        clf.fit(x_tr_single, y_tr_single)\n",
    "        predictions = clf.predict(x_ts_single)\n",
    "\n",
    "        return sklearn.metrics.r2_score(y_ts_single, predictions)\n",
    "    \n",
    "# #     level prediction\n",
    "\n",
    "#     for item in y_tr.columns:\n",
    "#         if '_5o5' in item or '_qoq' in item or '_aoa' in item:\n",
    "#             continue    \n",
    "#         param_test = {'max_depth': [1, 6], 'num_leaves': [2, 4], 'n_estimators': [20, 100, 500]}\n",
    "# #         param_test = {'max_depth': [1], 'num_leaves': [2], 'n_estimators': [5]}\n",
    "#         mod = LGBMRegressor(objective='regression_l2', zero_as_missing=True)\n",
    "#         clf = sklearn.model_selection.GridSearchCV(mod , param_grid = param_test, scoring='r2', cv=3)\n",
    "#         clf.fit(x_tr.values, y_tr[item].values)\n",
    "#         predictions = clf.predict(x_ts.values)\n",
    "#         y_true = y_ts[item].values \n",
    "        \n",
    "#         if plot is True: \n",
    "#             plt.bar(range(len(clf.best_estimator_.feature_importances_)), clf.best_estimator_.feature_importances_)\n",
    "#             plt.title(str(tr_start) + ' ' + item)\n",
    "#             plt.show()\n",
    "            \n",
    "#         max_fea = []\n",
    "#         max_5 = clf.best_estimator_.feature_importances_.argsort()[-5:][::-1]\n",
    "#         for index in max_5:\n",
    "#             max_fea.append(x_tr.columns[index])\n",
    "#         oosr2[item] = sklearn.metrics.r2_score(y_true, predictions)\n",
    "#         try:\n",
    "#             sig_feature_oosr2 = single_feature_oosr2(item, param_test=param_test)\n",
    "#             enhancement = (oosr2[item] - sig_feature_oosr2)/sig_feature_oosr2\n",
    "#             print(tr_start, item, oosr2[item], enhancement, max_fea)\n",
    "#             print(clf.best_params_)\n",
    "#             oosr2single[item] = sig_feature_oosr2\n",
    "#         except KeyError:\n",
    "#             print(item, oosr2[item], max_fea)\n",
    "#             print(clf.best_params_)\n",
    "            \n",
    "            \n",
    "    # year on year growth prediction\n",
    "\n",
    "    for item in y_tr.columns:\n",
    "        if '_aoa' not in item:\n",
    "            continue    \n",
    "        param_test = {'max_depth': [1, 6], 'num_leaves': [2, 4], 'n_estimators': [20, 100, 500]}\n",
    "#         param_test = {'max_depth': [1], 'num_leaves': [2], 'n_estimators': [20, 100, 500]}\n",
    "        mod = LGBMRegressor(objective='regression_l2', zero_as_missing=True)\n",
    "        clf = sklearn.model_selection.GridSearchCV(mod , param_grid = param_test, scoring='r2', cv=5)\n",
    "        clf.fit(x_tr.values, y_tr[item].values)\n",
    "        predictions = clf.predict(x_ts.values)\n",
    "        y_true = y_ts[item].values \n",
    "        plt.bar(range(len(clf.best_estimator_.feature_importances_)), clf.best_estimator_.feature_importances_)\n",
    "        plt.show()\n",
    "        max_fea = []\n",
    "        max_5 = clf.best_estimator_.feature_importances_.argsort()[-5:][::-1]\n",
    "        for index in max_5:\n",
    "            max_fea.append(x_tr.columns[index])\n",
    "        max1[item], max2[item], max3[item], max4[item], max5[item] = max_fea[0], max_fea[1], max_fea[2], max_fea[3], max_fea[4] \n",
    "        oosr2[item] = sklearn.metrics.r2_score(y_true, predictions)\n",
    "        try:\n",
    "            sig_feature_oosr2 = single_feature_oosr2(item, param_test=param_test)\n",
    "            enhancement = (oosr2[item] - sig_feature_oosr2)/sig_feature_oosr2\n",
    "            oosr2single[item] = sig_feature_oosr2\n",
    "            print(tr_start, item, oosr2[item], enhancement, max_fea)\n",
    "            print(clf.best_params_)\n",
    "        except KeyError:\n",
    "            print(item, oosr2[item], max_fea)\n",
    "            print(clf.best_params_)\n",
    "    \n",
    "    return oosr2, oosr2single, max1, max2, max3, max4, max5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004]\n",
      "[2005]\n"
     ]
    }
   ],
   "source": [
    "oosr2df, oosr2singledf, max1df, max2df, max3df, max4df, max5df = None, None, None,None,None,None,None\n",
    "\n",
    "start_training_year = 1975\n",
    "end_training_year = 2018\n",
    "\n",
    "for tr_start in range(start_training_year, end_training_year, 1):\n",
    "    \n",
    "    oosr2, oosr2single, max1, max2, max3, max4, max5 = train_test_process(tr_start=tr_start, tr_duration=30, ts_duration=1, dy=0, dq=1)\n",
    "    \n",
    "    if oosr2df is None:\n",
    "        oosr2df = pd.DataFrame.from_dict(oosr2, orient='index', columns=[tr_start])\n",
    "        oosr2singledf = pd.DataFrame.from_dict(oosr2single, orient='index', columns=[tr_start])\n",
    "        max1df = pd.DataFrame.from_dict(max1, orient='index', columns=[tr_start])\n",
    "        max2df = pd.DataFrame.from_dict(max2, orient='index', columns=[tr_start])\n",
    "        max3df = pd.DataFrame.from_dict(max3, orient='index', columns=[tr_start])\n",
    "        max4df = pd.DataFrame.from_dict(max4, orient='index', columns=[tr_start])\n",
    "        max5df = pd.DataFrame.from_dict(max5, orient='index', columns=[tr_start])\n",
    "        \n",
    "    else:\n",
    "        oosr2df = pd.concat([oosr2df, pd.DataFrame.from_dict(oosr2, orient='index', columns=[tr_start])], axis=1)\n",
    "        oosr2singledf = pd.concat([oosr2singledf, pd.DataFrame.from_dict(oosr2single, orient='index', columns=[tr_start])], axis=1)\n",
    "        max1df = pd.concat([max1df, pd.DataFrame.from_dict(max1, orient='index', columns=[tr_start])], axis=1)\n",
    "        max2df = pd.concat([max2df, pd.DataFrame.from_dict(max2, orient='index', columns=[tr_start])], axis=1)\n",
    "        max3df = pd.concat([max3df, pd.DataFrame.from_dict(max3, orient='index', columns=[tr_start])], axis=1)\n",
    "        max4df = pd.concat([max4df, pd.DataFrame.from_dict(max4, orient='index', columns=[tr_start])], axis=1)\n",
    "        max5df = pd.concat([max5df, pd.DataFrame.from_dict(max5, orient='index', columns=[tr_start])], axis=1)\n",
    "    \n",
    "    oosr2df.to_csv(os.path.join('/Users/mmw/Documents/GitHub/ml_val/train/rl_result', '_'.join([\"oosr2\", 'q', str(0), str(1), str(start_training_year), str(end_training_year)]) + '.csv'))\n",
    "    oosr2singledf.to_csv(os.path.join('/Users/mmw/Documents/GitHub/ml_val/train/rl_result', '_'.join([\"oosr2single\", 'q', str(0), str(1), str(start_training_year), str(end_training_year)]) + '.csv'))\n",
    "    max1df.to_csv(os.path.join('/Users/mmw/Documents/GitHub/ml_val/train/rl_result', '_'.join([\"max1\", 'q', str(0), str(1), str(start_training_year), str(end_training_year)]) + '.csv'))\n",
    "    max2df.to_csv(os.path.join('/Users/mmw/Documents/GitHub/ml_val/train/rl_result', '_'.join([\"max2\", 'q', str(0), str(1), str(start_training_year), str(end_training_year)]) + '.csv'))\n",
    "    max3df.to_csv(os.path.join('/Users/mmw/Documents/GitHub/ml_val/train/rl_result', '_'.join([\"max3\", 'q', str(0), str(1), str(start_training_year), str(end_training_year)]) + '.csv'))\n",
    "    max4df.to_csv(os.path.join('/Users/mmw/Documents/GitHub/ml_val/train/rl_result', '_'.join([\"max4\", 'q', str(0), str(1), str(start_training_year), str(end_training_year)]) + '.csv'))\n",
    "    max5df.to_csv(os.path.join('/Users/mmw/Documents/GitHub/ml_val/train/rl_result', '_'.join([\"max5\", 'q', str(0), str(1), str(start_training_year), str(end_training_year)]) + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
